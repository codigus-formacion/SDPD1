{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/maes/.sdkman/candidates/java/current'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# En nuestro ordenador personal, si no esta definida la variable JAVA_HOME, deberemos indicarla\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
    "\n",
    "# En los laboratorios docentes, sera necesario utilizar la siguiente\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/\"\n",
    "\n",
    "os.environ[\"JAVA_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.58:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Bike rental</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x704fd0b0cee0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.cores\", 1)\n",
    "    .appName(\"Bike rental\")\n",
    "    .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to explore a dataset generated from a bike rental system deployed in San Francisco area. The dataset consist of two data sources: \n",
    "- information about the renting stations\n",
    "- information about trips done using this service\n",
    "\n",
    "Next, we will explore both of them and compute some new information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration\n",
    "\n",
    "The first dataset contains information about the renting stations. We can use spark's csv reader to take a look at the data. Because the dataset contains an initial entry with the field names, we must provide the reader with the corresponding option take the header into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = spark.read.option(\"header\", \"true\").csv(\"data/bike-data/201508_station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|station_id|                name|      lat|       long|dockcount|landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|         2|San Jose Diridon ...|37.329732|-121.901782|       27|San Jose|    8/6/2013|\n",
      "|         3|San Jose Civic Ce...|37.330698|-121.888979|       15|San Jose|    8/5/2013|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- dockcount: string (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the output of the previous statements, the schema inference has not worked very well. Moreover, the installation date uses a non standard format.\n",
    "\n",
    "To get the most of our process we will provide a custom schema to coherce the data types to the proper ones. In addition, we also pass the `dateFormat` option to the Spark DataFrameReaer to parse the installation data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationSchema = StructType([StructField(\"station_id\", ByteType(), False), \n",
    "                           StructField(\"name\", StringType(), False),\n",
    "                           StructField(\"lat\", DoubleType(), False),\n",
    "                           StructField(\"long\", DoubleType(), False),\n",
    "                           StructField(\"dockcount\", IntegerType(), False),\n",
    "                           StructField(\"landmark\", StringType(), False),\n",
    "                           StructField(\"installation\", DateType(), False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In Spark 3.X, the date format MM/dd/yyyy is not longer valid, we need to use M/d/yyyy\" instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = spark.read.option(\"header\", \"true\").option(\"dateFormat\", \"M/d/yyyy\").csv(\"data/bike-data/201508_station_data.csv\", schema=stationSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: byte (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After providing the proper schema we are able to load the dataset wihtout formatting issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------+---------+-----------+---------+------------+------------+\n",
      "|station_id|name                             |lat      |long       |dockcount|landmark    |installation|\n",
      "+----------+---------------------------------+---------+-----------+---------+------------+------------+\n",
      "|2         |San Jose Diridon Caltrain Station|37.329732|-121.901782|27       |San Jose    |2013-08-06  |\n",
      "|3         |San Jose Civic Center            |37.330698|-121.888979|15       |San Jose    |2013-08-05  |\n",
      "|4         |Santa Clara at Almaden           |37.333988|-121.894902|11       |San Jose    |2013-08-06  |\n",
      "|5         |Adobe on Almaden                 |37.331415|-121.8932  |19       |San Jose    |2013-08-05  |\n",
      "|6         |San Pedro Square                 |37.336721|-121.894074|15       |San Jose    |2013-08-07  |\n",
      "|7         |Paseo de San Antonio             |37.333798|-121.886943|15       |San Jose    |2013-08-07  |\n",
      "|8         |San Salvador at 1st              |37.330165|-121.885831|15       |San Jose    |2013-08-05  |\n",
      "|9         |Japantown                        |37.348742|-121.894715|15       |San Jose    |2013-08-05  |\n",
      "|10        |San Jose City Hall               |37.337391|-121.886995|15       |San Jose    |2013-08-06  |\n",
      "|11        |MLK Library                      |37.335885|-121.88566 |19       |San Jose    |2013-08-06  |\n",
      "|12        |SJSU 4th at San Carlos           |37.332808|-121.883891|19       |San Jose    |2013-08-07  |\n",
      "|13        |St James Park                    |37.339301|-121.889937|15       |San Jose    |2013-08-06  |\n",
      "|14        |Arena Green / SAP Center         |37.332692|-121.900084|19       |San Jose    |2013-08-05  |\n",
      "|16        |SJSU - San Salvador at 9th       |37.333955|-121.877349|15       |San Jose    |2013-08-07  |\n",
      "|21        |Franklin at Maple                |37.481758|-122.226904|15       |Redwood City|2013-08-12  |\n",
      "|22        |Redwood City Caltrain Station    |37.486078|-122.232089|25       |Redwood City|2013-08-15  |\n",
      "|23        |San Mateo County Center          |37.487616|-122.229951|15       |Redwood City|2013-08-15  |\n",
      "|24        |Redwood City Public Library      |37.484219|-122.227424|15       |Redwood City|2013-08-12  |\n",
      "|25        |Stanford in Redwood City         |37.48537 |-122.203288|15       |Redwood City|2013-08-12  |\n",
      "|26        |Redwood City Medical Center      |37.487682|-122.223492|15       |Redwood City|2013-08-12  |\n",
      "+----------+---------------------------------+---------+-----------+---------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "The station dataset contains information about the location and characteristics of the stations installed for the rental service.\n",
    "\n",
    "Let's do a little summary to compute for each landmark the date when the first station was deployed, the date of the last update and the total number of docks available for the area so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = (\n",
    "    stations.\n",
    "    groupBy(\"landmark\").\n",
    "    agg(\n",
    "        min(\"installation\").alias(\"service_start\"),\n",
    "        max(\"installation\").alias(\"last_update\"),\n",
    "        sum(\"dockcount\").alias(\"total_docks\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----------+-----------+\n",
      "|     landmark|service_start|last_update|total_docks|\n",
      "+-------------+-------------+-----------+-----------+\n",
      "|     San Jose|   2013-08-05| 2014-04-09|        264|\n",
      "| Redwood City|   2013-08-12| 2014-02-20|        115|\n",
      "|    Palo Alto|   2013-08-14| 2013-08-15|         75|\n",
      "|Mountain View|   2013-08-15| 2013-12-31|        117|\n",
      "|San Francisco|   2013-08-19| 2014-01-22|        665|\n",
      "+-------------+-------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(landmarks.\n",
    " orderBy(col(\"service_start\")).\n",
    " show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration\n",
    "\n",
    "The second dataset contains information about registered trips using the rental service.\n",
    "\n",
    "Again, we make use of the csv reader to take out the initial exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.option(\"header\", \"true\").csv(\"data/bike-data/201508_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+----+---------------+--------+\n",
      "|trip_id|duration|     start_date|       start_station|start_terminal|       end_date|         end_station|end_terminal|bike|subscriber_type|zip_code|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+----+---------------+--------+\n",
      "| 913460|     765|8/31/2015 23:26|Harry Bridges Pla...|            50|8/31/2015 23:39|San Francisco Cal...|          70| 288|     Subscriber|    2139|\n",
      "| 913459|    1036|8/31/2015 23:11|San Antonio Shopp...|            31|8/31/2015 23:28|Mountain View Cit...|          27|  35|     Subscriber|   95032|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+----+---------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- start_date: string (nullable = true)\n",
      " |-- start_station: string (nullable = true)\n",
      " |-- start_terminal: string (nullable = true)\n",
      " |-- end_date: string (nullable = true)\n",
      " |-- end_station: string (nullable = true)\n",
      " |-- end_terminal: string (nullable = true)\n",
      " |-- bike: string (nullable = true)\n",
      " |-- subscriber_type: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the previous execution, field types are not inferred and the format of the timesatmps is not an standard one. To parse it propertly we will define the schema manually and also provide the `timestampFormat` option to the DataFrameReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripSchema = StructType([StructField(\"trip_id\", IntegerType(), False), \n",
    "                         StructField(\"duration\", IntegerType(), False),\n",
    "                         StructField(\"start_date\", TimestampType(), False),\n",
    "                         StructField(\"start_station\", StringType(), False),\n",
    "                         StructField(\"start_terminal\", ByteType(), False),\n",
    "                         StructField(\"end_date\", TimestampType(), False),\n",
    "                         StructField(\"end_station\", StringType(), False),\n",
    "                         StructField(\"end_terminal\", ByteType(), False),\n",
    "                         StructField(\"bike\", IntegerType(), False),\n",
    "                         StructField(\"subscriber_type\", StringType(), False),\n",
    "                         StructField(\"zip_code\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = (spark.read.option(\"header\", \"true\")\n",
    "         .option(\"timestampFormat\", \"M/d/yyyy HH:mm\")\n",
    "         .csv(\"data/bike-data/201508_trip_data.csv\", schema=tripSchema)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------------------+--------------------+--------------+-------------------+--------------------+------------+----+---------------+--------+\n",
      "|trip_id|duration|         start_date|       start_station|start_terminal|           end_date|         end_station|end_terminal|bike|subscriber_type|zip_code|\n",
      "+-------+--------+-------------------+--------------------+--------------+-------------------+--------------------+------------+----+---------------+--------+\n",
      "| 913460|     765|2015-08-31 23:26:00|Harry Bridges Pla...|            50|2015-08-31 23:39:00|San Francisco Cal...|          70| 288|     Subscriber|    2139|\n",
      "| 913459|    1036|2015-08-31 23:11:00|San Antonio Shopp...|            31|2015-08-31 23:28:00|Mountain View Cit...|          27|  35|     Subscriber|   95032|\n",
      "| 913455|     307|2015-08-31 23:13:00|      Post at Kearny|            47|2015-08-31 23:18:00|   2nd at South Park|          64| 468|     Subscriber|   94107|\n",
      "| 913454|     409|2015-08-31 23:10:00|  San Jose City Hall|            10|2015-08-31 23:17:00| San Salvador at 1st|           8|  68|     Subscriber|   95113|\n",
      "| 913453|     789|2015-08-31 23:09:00|Embarcadero at Fo...|            51|2015-08-31 23:22:00|Embarcadero at Sa...|          60| 487|       Customer|    9069|\n",
      "| 913452|     293|2015-08-31 23:07:00|Yerba Buena Cente...|            68|2015-08-31 23:12:00|San Francisco Cal...|          70| 538|     Subscriber|   94118|\n",
      "| 913451|     896|2015-08-31 23:07:00|Embarcadero at Fo...|            51|2015-08-31 23:22:00|Embarcadero at Sa...|          60| 363|       Customer|   92562|\n",
      "| 913450|     255|2015-08-31 22:16:00|Embarcadero at Sa...|            60|2015-08-31 22:20:00|   Steuart at Market|          74| 470|     Subscriber|   94111|\n",
      "| 913449|     126|2015-08-31 22:12:00|     Beale at Market|            56|2015-08-31 22:15:00|Temporary Transba...|          55| 439|     Subscriber|   94130|\n",
      "| 913448|     932|2015-08-31 21:57:00|      Post at Kearny|            47|2015-08-31 22:12:00|South Van Ness at...|          66| 472|     Subscriber|   94702|\n",
      "| 913443|     691|2015-08-31 21:49:00|Embarcadero at Sa...|            60|2015-08-31 22:01:00|   Market at Sansome|          77| 434|     Subscriber|   94109|\n",
      "| 913442|     633|2015-08-31 21:44:00|      Market at 10th|            67|2015-08-31 21:54:00|San Francisco Cal...|          70| 531|     Subscriber|   94107|\n",
      "| 913441|     387|2015-08-31 21:39:00|       Market at 4th|            76|2015-08-31 21:46:00|Grant Avenue at C...|          73| 383|     Subscriber|   94104|\n",
      "| 913440|     281|2015-08-31 21:31:00|   Market at Sansome|            77|2015-08-31 21:36:00|Broadway St at Ba...|          82| 621|     Subscriber|   94107|\n",
      "| 913435|     424|2015-08-31 21:25:00|Temporary Transba...|            55|2015-08-31 21:33:00|San Francisco Cal...|          69| 602|     Subscriber|   94401|\n",
      "| 913434|     283|2015-08-31 21:19:00|San Francisco Cal...|            69|2015-08-31 21:24:00|     Townsend at 7th|          65| 521|     Subscriber|   94107|\n",
      "| 913433|     145|2015-08-31 21:17:00|University and Em...|            35|2015-08-31 21:20:00|Cowper at University|          37|  75|       Customer|    6907|\n",
      "| 913432|     703|2015-08-31 21:16:00|     Spear at Folsom|            49|2015-08-31 21:28:00|San Francisco Cal...|          69| 426|     Subscriber|   95032|\n",
      "| 913431|     605|2015-08-31 21:11:00|Temporary Transba...|            55|2015-08-31 21:21:00|Grant Avenue at C...|          73| 572|     Subscriber|   94133|\n",
      "| 913429|     902|2015-08-31 21:07:00|San Francisco Cal...|            70|2015-08-31 21:22:00|Broadway St at Ba...|          82| 501|     Subscriber|   94133|\n",
      "+-------+--------+-------------------+--------------------+--------------+-------------------+--------------------+------------+----+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.show(truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354152"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Compute the total number of trips, the total trip duration (hours) and the average trip duration (minutes) for each bike, and display a ranking for the top 5 most used with the corresponding stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_info = (\n",
    "    trips.\n",
    "    groupBy(\"bike\").\n",
    "    agg(\n",
    "        count(\"*\").alias(\"total\"),\n",
    "        (round(sum(\"duration\")/3600,2)).alias(\"total_duration(hours)\"),\n",
    "        (round(avg(\"duration\")/60, 2)).alias(\"avg_duration(mins)\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------------+------------------+\n",
      "|bike|total|total_duration(hours)|avg_duration(mins)|\n",
      "+----+-----+---------------------+------------------+\n",
      "| 878| 1121|               279.67|             14.97|\n",
      "| 392| 1102|               284.41|             15.49|\n",
      "| 489| 1101|               238.35|             12.99|\n",
      "| 463| 1085|               279.98|             15.48|\n",
      "| 532| 1074|               237.33|             13.26|\n",
      "+----+-----+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "(bike_info.\n",
    " orderBy(bike_info.total.desc()).\n",
    " show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a summary (see function `describe()`)of the aggretated dataset containing information about how the bikes are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+---------------------+------------------+\n",
      "|summary|            total|total_duration(hours)|avg_duration(mins)|\n",
      "+-------+-----------------+---------------------+------------------+\n",
      "|  count|              668|                  668|               668|\n",
      "|   mean|530.1676646706587|    154.0480239520958| 22.65806886227546|\n",
      "| stddev|398.3555876917163|   210.80905043525703| 32.21889509608674|\n",
      "|    min|                4|                 0.54|              4.63|\n",
      "|    max|             1121|               4920.8|            646.06|\n",
      "+-------+-----------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bike_info.drop(\"bike\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know how individual trips look like, we can describe the initial dataset before being aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|    duration(mins)|\n",
      "+-------+------------------+\n",
      "|  count|            354152|\n",
      "|   mean|17.433877685287612|\n",
      "| stddev| 500.2822692821593|\n",
      "|    min|               1.0|\n",
      "|    max|          287840.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips.select((col('duration')/60).alias('duration(mins)')).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Compute the minimun distance traveled for a bike trip. We will consider the minimum trip distance to the distance between the starting and ending stations.\n",
    "\n",
    "We will use the haversine distante provided to compute the distance between two geographical points stated by their (long, lat) coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_coords = stations.selectExpr(\"station_id as start_terminal\", \"lat as start_lat\", \"long as start_long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_coords = stations.selectExpr(\"station_id as end_terminal\", \"lat as end_lat\", \"long as end_long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you will need to use the `join()` function to add the coordinates to each trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_coords = (\n",
    "    trips.\n",
    "    select('trip_id', 'bike', 'start_terminal', 'end_terminal', 'duration').\n",
    "    join(start_coords, 'start_terminal', 'inner').\n",
    "    join(end_coords, 'end_terminal') # default join type is inner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------+----+--------+---------+-----------+---------+-----------+\n",
      "|end_terminal|start_terminal|trip_id|bike|duration|start_lat| start_long|  end_lat|   end_long|\n",
      "+------------+--------------+-------+----+--------+---------+-----------+---------+-----------+\n",
      "|          70|            50| 913460| 288|     765|37.795392|-122.394203|37.776617| -122.39526|\n",
      "|          27|            31| 913459|  35|    1036|37.400443|-122.108338|37.389218|-122.081896|\n",
      "|          64|            47| 913455| 468|     307|37.788975|-122.403452|37.782259|-122.392738|\n",
      "|           8|            10| 913454|  68|     409|37.337391|-121.886995|37.330165|-121.885831|\n",
      "|          60|            51| 913453| 487|     789|37.791464|-122.391034| 37.80477|-122.403234|\n",
      "|          70|            68| 913452| 538|     293|37.784878|-122.401014|37.776617| -122.39526|\n",
      "|          60|            51| 913451| 363|     896|37.791464|-122.391034| 37.80477|-122.403234|\n",
      "|          74|            60| 913450| 470|     255| 37.80477|-122.403234|37.794139|-122.394434|\n",
      "|          55|            56| 913449| 439|     126|37.792251|-122.397086|37.789756|-122.394643|\n",
      "|          66|            47| 913448| 472|     932|37.788975|-122.403452|37.774814|-122.418954|\n",
      "+------------+--------------+-------+----+--------+---------+-----------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_coords.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to calculate the distance is a function defined by us. We have to use `udf(...)` (User Defined Function) to convert it into a spark compatible function. It will allow us to pass as parameters the names of the fields and our function will obtain the corresponding values.\n",
    "\n",
    "**Note**: These functions are usually the most computationally expensive, as they are not optimised. More info: https://sparkbyexamples.com/pyspark/pyspark-udf-user-defined-function/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine_udf = udf(haversine, DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we can now calculate the distance of each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_trips = (\n",
    "    trip_coords.\n",
    "    select(\n",
    "        'trip_id',\n",
    "        'bike',\n",
    "        'duration',\n",
    "        haversine_udf('start_long', 'start_lat', 'end_long', 'end_lat').alias('distance')\n",
    "    )\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------+-------------------+\n",
      "|trip_id|bike|duration|           distance|\n",
      "+-------+----+--------+-------------------+\n",
      "| 449868|  97|     593|0.01855324879480863|\n",
      "| 757653| 418|    8682|0.01855324879480863|\n",
      "| 648319| 392|     115|0.01855324879480863|\n",
      "| 736456| 436|    4285|0.01855324879480863|\n",
      "| 842718| 514|   17738|0.01855324879480863|\n",
      "| 772900| 349|    1172|0.01855324879480863|\n",
      "| 653113| 339|   14373|0.01855324879480863|\n",
      "| 777616| 314|    1780|0.01855324879480863|\n",
      "| 911100| 380|    2973|0.01855324879480863|\n",
      "| 776085| 359|   33831|0.01855324879480863|\n",
      "| 652903| 490|    2314|0.01855324879480863|\n",
      "| 773425| 291|    1646|0.01855324879480863|\n",
      "| 842984| 395|   26321|0.01855324879480863|\n",
      "| 773303| 389|     862|0.01855324879480863|\n",
      "| 652058| 490|   12081|0.01855324879480863|\n",
      "| 770223| 579|    3909|0.01855324879480863|\n",
      "| 488917| 629|    1400|0.01855324879480863|\n",
      "| 770222| 326|    3895|0.01855324879480863|\n",
      "| 648692| 424|    1040|0.01855324879480863|\n",
      "| 763841| 524|     129|0.01855324879480863|\n",
      "+-------+----+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bike_trips.orderBy(col(\"distance\")).where(bike_trips.distance > 0).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
